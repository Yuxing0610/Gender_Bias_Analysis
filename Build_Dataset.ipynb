{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA_fe4oxWT6p"
   },
   "source": [
    "# Mounting the Google Drive\n",
    "\n",
    "First, mount the google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEcIlRwfWY4C",
    "outputId": "ca009ebf-1edb-4ce2-841c-b87dfd38d19a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PHsYlfK7e5a"
   },
   "source": [
    "# Build dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jwv0XY95IOoz"
   },
   "source": [
    "We intend to extract datasets of various mainstream media like New York Times and Fox News of different categories from the whole dataset provided. The following code is to generate the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pAPhTqRtdHQh"
   },
   "outputs": [],
   "source": [
    "# We try to split the dataset of one media into seven topics.\n",
    "# The map maps the categories to the keywords. \n",
    "# We try to reuse the categorizing result of the original website and investigate the patterns of the url of different media websites. \n",
    "# If the url of the quotation contains those keywords, we assume that the quotation belongs to the categories.\n",
    "\n",
    "categories = {\n",
    "'politics': ['/politics/', '/us/', '/world/', '/business/', '/opinion/', '/economy/', '/finance/', '/market/'],\n",
    "'technology': ['/tech/', '/science/'],\n",
    "'health': ['/health/'],\n",
    "'sports': ['/sports/'],\n",
    "'arts': ['/art/', '/arts/', '/movie/', '/fashion/', '/book/', '/books/' '/style/', '/music/', '/entertainment/'],\n",
    "'lifestyle': ['/food/', '/travel/', '/lifestyle/', '/auto/'],\n",
    "'uncategorized': ['/']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zskZSNwdeWZS",
    "outputId": "a46b5bce-ce1c-4ba0-d6e3-9873c94141a4"
   },
   "outputs": [],
   "source": [
    "# Import the packages we need.\n",
    "\n",
    "import bz2\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare the necessary path data and file handlers.\n",
    "\n",
    "years = ['2015', '2016', '2017', '2018', '2019', '2020']\n",
    "path_to_file_list = ['/content/drive/MyDrive/Quotebank/quotes-' + year + '.json.bz2' for year in years]\n",
    "path_to_out_list = ['/content/drive/Shareddrives/ADA/foxnews/'+year+'/quotes-' + year + '-fox-all.json.bz2' for year in years]\n",
    "gender_file_list = ['/content/drive/MyDrive/quotes-' + year + '-fox-gender.json.bz2' for year in years]\n",
    "\n",
    "maps = []\n",
    "for year in years:\n",
    "  cat_to_file = {}\n",
    "  for cat in categories:\n",
    "    path = '/content/drive/MyDrive/quotes-' + year + '-fox-' + cat + '.json.bz2'\n",
    "    cat_to_file[cat] = bz2.open(path, 'wb')\n",
    "  maps.append(cat_to_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjCaa8GNSKrL"
   },
   "outputs": [],
   "source": [
    "# Select the quotations according the prementioned rules and write them to new files.\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "  path_to_file = path_to_file_list[i]\n",
    "  path_to_out = path_to_out_list[i]\n",
    "  with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "      for instance in s_file: \n",
    "        instance = json.loads(instance) # loading a sample\n",
    "        urls = instance['urls'] # extracting list of links\n",
    "        is_media = False\n",
    "        category = None\n",
    "        for url in urls:\n",
    "          o = urlparse(url)\n",
    "          if 'foxnews' in o.netloc:\n",
    "            for cat in categories:\n",
    "              for keyword in categories[cat]:\n",
    "                if keyword in o.path:\n",
    "                  category = cat\n",
    "                  is_media = True\n",
    "                  break\n",
    "              if is_media:\n",
    "                break\n",
    "            if is_media:\n",
    "              break\n",
    "        if not is_media:\n",
    "          continue\n",
    "    \n",
    "        instance['category'] = category\n",
    "        d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) \n",
    "\n",
    "  with bz2.open(path_to_out, 'rb') as s_file:\n",
    "    for instance in s_file:\n",
    "      instance = json.loads(instance)\n",
    "      cat = instance['category']\n",
    "      maps[i][cat].write((json.dumps(instance)+'\\n').encode('utf-8')) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output dataset of Foxnews in 2015:\n",
    "\n",
    "![WeChat Image_20211111203434](https://user-images.githubusercontent.com/34649843/141358651-64ff392f-a3c6-446f-8282-43053d1855fe.png)\n",
    "\n",
    "![WeChat Image_20211111203500](https://user-images.githubusercontent.com/34649843/141358659-70f15cfe-f79e-4c6e-af1e-57e9cc712d57.png)\n",
    "\n",
    "The datasets of other medias and other years are organized similarly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avb2Rr0xVx5e"
   },
   "source": [
    "We also want to extract the gender related quotations from the dataset. We prepared a gender related word list. If a quotation or its url contains some words in the list, we assume it to be gender related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WccaZaGE6prk"
   },
   "outputs": [],
   "source": [
    "# Load the gender word list.\n",
    "\n",
    "with open('/content/drive/Shareddrives/ADA/gender related words.txt', 'r') as infile:\n",
    "  words = infile.readlines()\n",
    "\n",
    "gender_word_set = set([w.strip() for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8NQwb4IixAB"
   },
   "outputs": [],
   "source": [
    "# Preprocess the text.\n",
    "\n",
    "def clean_text(text):\n",
    "    # To remove the punctuations\n",
    "    text = text.translate(str.maketrans(' ',' ',string.punctuation))\n",
    "    # To consider only alphabets and numerics\n",
    "    text = re.sub('[^a-zA-Z]',' ',text) \n",
    "    # To replace newline with space\n",
    "    text = re.sub(\"\\n\",\" \",text)\n",
    "    # To convert to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-30Oa4TpWOfh"
   },
   "outputs": [],
   "source": [
    "# Select the quotations according the prementioned rules and write them to new files.\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "  path_to_file = path_to_out_list[i]\n",
    "  path_to_out = gender_file_list[i]\n",
    "  with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "      for instance in s_file: \n",
    "        instance = json.loads(instance)\n",
    "        urls = instance['urls']\n",
    "        quotation = instance['quotation']\n",
    "\n",
    "        is_gender_related = False\n",
    "        \n",
    "        for url in urls:\n",
    "          o = urlparse(url)\n",
    "          path = clean_text(o.path)\n",
    "          for w in path:\n",
    "            if w in gender_word_set:\n",
    "              is_gender_related = True\n",
    "\n",
    "          if is_gender_related:\n",
    "            break\n",
    "\n",
    "        if not is_gender_related:\n",
    "          quotation = clean_text(quotation)\n",
    "          for w in quotation:\n",
    "            if w in gender_word_set:\n",
    "              is_gender_related = True\n",
    "              break\n",
    "\n",
    "        if is_gender_related:\n",
    "          d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output dataset of foxnews is organized as follows:\n",
    "\n",
    "![WeChat Image_20211111204329](https://user-images.githubusercontent.com/34649843/141359086-7332ac51-6e50-4b85-a7d1-c090be8b3617.png)\n",
    "\n",
    "The datasets of other medias are organized similarly."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
